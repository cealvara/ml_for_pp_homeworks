{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# HW 1 - Carlos Alvarado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_and_load_data(data_info):\n",
    "    '''\n",
    "    Loads \"data_name.csv\" from local disk, or downloads it if it's not present\n",
    "    \n",
    "    Input: dictionary with information about required data\n",
    "    Returns: pandas data_frame for \"data_name\"\n",
    "    '''\n",
    "    \n",
    "    filepath = './data/{}.csv'.format(data_info['source'])\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        data = pd.read_csv(filepath)\n",
    "    else:\n",
    "        data = helper_download_data(filepath, data_name)\n",
    "    \n",
    "    for old_var, new_var in data_info['rename']:\n",
    "        data.rename(index=str, columns={old_var: new_var}, inplace=True)\n",
    "        \n",
    "    return data\n",
    "    \n",
    "def helper_download_data(filepath, data_name):\n",
    "    offset = 0\n",
    "    limit = 50000\n",
    "    data = pd.DataFrame({})\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        url = 'https://data.cityofchicago.org/resource/{}.json?$limit={}&$offset={}'.format(\n",
    "            data_name, limit, offset)\n",
    "        print('getting data from', url)\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        response_code = response.status_code\n",
    "        \n",
    "        if response_code != 200: \n",
    "            print('Failed to download data')\n",
    "            break\n",
    "            \n",
    "        json_data = response.content\n",
    "\n",
    "        if len(json_data) > 4:\n",
    "            data = pd.concat([data, pd.read_json(json_data)])\n",
    "        \n",
    "            offset = offset + limit\n",
    "        else:\n",
    "            print(json_data)\n",
    "            break\n",
    "            \n",
    "    #save data to csv for future use\n",
    "    data.to_csv(filepath)\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'community_area', 'completion_date', 'creation_date',\n",
      "       'latitude', 'location', 'longitude', 'police_district',\n",
      "       'service_request_number', 'ssa', 'status', 'street_address',\n",
      "       'type_of_service_request', 'ward',\n",
      "       'what_type_of_surface_is_the_graffiti_on_', 'Sub Type', 'x_coordinate',\n",
      "       'y_coordinate', 'zip_code'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'address_street_direction', 'address_street_name',\n",
      "       'address_street_number', 'address_street_suffix',\n",
      "       'any_people_using_property_homeless_childen_gangs_', 'community_area',\n",
      "       'creation_date', 'if_the_building_is_open_where_is_the_entry_point_',\n",
      "       'Sub Type', 'is_the_building_currently_vacant_or_occupied_',\n",
      "       'is_the_building_dangerous_or_hazardous_',\n",
      "       'is_the_building_vacant_due_to_fire_', 'latitude', 'location',\n",
      "       'location_of_building_on_the_lot_if_garage_change_type_code_to_bgd_',\n",
      "       'longitude', 'police_district', 'service_request_number',\n",
      "       'service_request_type', 'ward', 'x_coordinate', 'y_coordinate',\n",
      "       'zip_code'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'community_area', 'completion_date', 'creation_date',\n",
      "       'current_activity', 'latitude', 'location', 'longitude',\n",
      "       'most_recent_action', 'number_of_potholes_filled_on_block',\n",
      "       'police_district', 'service_request_number', 'ssa', 'status',\n",
      "       'street_address', 'Sub Type', 'ward', 'x_coordinate', 'y_coordinate',\n",
      "       'zip_code'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'community_area', 'completion_date', 'creation_date',\n",
      "       'latitude', 'location', 'longitude', 'police_district',\n",
      "       'service_request_number', 'status', 'street_address',\n",
      "       'type_of_service_request', 'ward', 'Sub Type', 'x_coordinate',\n",
      "       'y_coordinate', 'zip_code'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py:3006: DtypeWarning: Columns (3,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "DATA1 = {'name': 'Graffiti Removal',\n",
    "         'source': 'hec5-y4x5',\n",
    "         'rename': [('where_is_the_graffiti_located_', 'Sub Type')]    \n",
    "        }\n",
    "\n",
    "DATA2 = {'name': 'Vacant and Abandoned Buildings Reported',\n",
    "         'source': '7nii-7srd',\n",
    "         'rename': [('is_building_open_or_boarded_', 'Sub Type'), \n",
    "                    ('date_service_request_was_received', 'creation_date')]\n",
    "        }\n",
    "\n",
    "DATA3 = {'name': 'Pot Holes Reported',\n",
    "         'source': '7as2-ds3y',\n",
    "         'rename': [('zip', 'zip_code'), \n",
    "                    ('type_of_service_request', 'Sub Type')]\n",
    "        }\n",
    "    \n",
    "DATA4 = {'name': 'Sanitation Code Complaints',\n",
    "         'source': 'me59-5fac',\n",
    "         'rename': [('what_is_the_nature_of_this_code_violation_', 'Sub Type')]\n",
    "        }\n",
    "\n",
    "SOURCES = [DATA1, DATA2, DATA3, DATA4]\n",
    "\n",
    "complaints = pd.DataFrame({})\n",
    "\n",
    "for db_data in SOURCES:\n",
    "    data = get_and_load_data(db_data)\n",
    "    print(data.columns)\n",
    "    data['Complaint Type'] = db_data['name']\n",
    "    complaints = pd.concat([complaints, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create sample database to play with\n",
    "complaints.sample(1000).to_csv('./data/sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "complaints.loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ctcounts = complaints['Complaint Type'].value_counts()\n",
    "ctcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gb = complaints.groupby(['Complaint Type', 'Sub Type']).size().to_frame()\n",
    "print(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gb_community_area = complaints.groupby(['Complaint Type', 'community_area']).size().to_frame()\n",
    "select = gb_community_area['0'] \n",
    "print(gb_community_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CRS does not match!\n"
     ]
    }
   ],
   "source": [
    "# Adding Block ID to 311 Requests data \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame\n",
    "from geopandas.tools import sjoin\n",
    "from shapely.geometry import Point\n",
    "\n",
    "blocks = gpd.read_file('./data/cb_2015_17_bg_500k/cb_2015_17_bg_500k.shp')\n",
    "#blocks = gpd.read_file('./data/boundaries/boundaries_census.geojson')\n",
    "\n",
    "#complaints = pd.read_csv('./data/sample.csv')\n",
    "\n",
    "clean_data = complaints[complaints['latitude'].notnull() & complaints['longitude'].notnull()]\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(clean_data.longitude, clean_data.latitude)]\n",
    "clean_data = clean_data.drop(['latitude', 'longitude'], axis=1)\n",
    "\n",
    "crs = {'init': 'epsg:4269'}\n",
    "geo_complaints = GeoDataFrame(clean_data, crs=crs, geometry=geometry)\n",
    "\n",
    "data_with_blockid = sjoin(geo_complaints, blocks, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crs = {'init': 'epsg:4269'}\n",
    "geo_complaints = GeoDataFrame(clean_data, crs=crs, geometry=geometry)\n",
    "\n",
    "data_with_blockid = sjoin(geo_complaints, blocks, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting census data\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_data_census(varname, label):\n",
    "\n",
    "    census_api_url = 'http://api.census.gov/data/' + \\\n",
    "                    '2015/acs5?get=NAME,' + varname + \\\n",
    "                    '&for=block+group:*&in=state:17&in=county:031&in=tract:*'\n",
    "\n",
    "    response = requests.get(census_api_url)\n",
    "\n",
    "    json_data = response.content\n",
    "\n",
    "    data = pd.read_json(json_data)\n",
    "\n",
    "    names = list(data.iloc[0])\n",
    "\n",
    "    for i in range(0,6):\n",
    "        data.rename(index=str, columns={i: names[i]}, inplace=True)\n",
    "    \n",
    "    data.rename(index=str, columns={varname: label}, inplace=True)\n",
    "    \n",
    "    data['GEOID'] = data['state'].map(str) + data['county'].map(str) + \\\n",
    "                            data['tract'].map(str) + data['block group'].map(str)\n",
    "\n",
    "    data.drop(data.index[[0]], inplace=True)\n",
    "    \n",
    "    print('downloaded', varname)\n",
    "    \n",
    "    return data\n",
    "\n",
    "download_data = [('B01003_001E', 'Total Population'),\n",
    "                ('B02001_002E', 'White Population'),\n",
    "                ('B19013_001E', 'Median Household Income'),\n",
    "                ('B06009_002E', 'Less than highschool')]\n",
    "\n",
    "for i, (varname, label) in enumerate(download_data):\n",
    "    downloaded = get_data_census(varname, label)\n",
    "    if i == 0:\n",
    "        census_data = downloaded\n",
    "    else:\n",
    "        census_data = census_data.merge(downloaded, on='GEOID', how='outer')\n",
    "\n",
    "data_with_blockid2 = data_with_blockid.merge(census_data, on='GEOID')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_with_blockid2 = data_with_blockid.merge(census_data, on='GEOID')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_with_blockid2.iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(blocks2.blockce10.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks2.countyfp10.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to make graphs\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "blocks.plot();\n",
    "\n",
    "base = blocks2.plot(color='white')\n",
    "\n",
    "geo_sel.plot(ax=base, marker='o', color='red', markersize=5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
